{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 0\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import time\n",
    "from scipy.stats import itemfreq\n",
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from compute_util import parallel_df, save_df, load_df, chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images():\n",
    "    \"\"\" Extract images from Avito's advertisement image zip archive \"\"\"\n",
    "\n",
    "    NUM_IMAGES_TO_EXTRACT = 50\n",
    "\n",
    "    with zipfile.ZipFile(os.path.join(DATA_PATH, IMG_ZIP_NAME), 'r') as train_zip:\n",
    "        files_in_zip = sorted(train_zip.namelist())\n",
    "        for idx, file in enumerate(files_in_zip[:NUM_IMAGES_TO_EXTRACT]):\n",
    "            if file.endswith('.jpg'):\n",
    "                train_zip.extract(file, path=IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_color(img):\n",
    "    arr = np.float32(img)\n",
    "    pixels = arr.reshape((-1, 3))\n",
    "\n",
    "    n_colors = 5\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, labels, centroids = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n",
    "\n",
    "    palette = np.uint8(centroids)\n",
    "    quantized = palette[labels.flatten()]\n",
    "    quantized = quantized.reshape(img.shape)\n",
    "\n",
    "    dominant_color = palette[np.argmax(itemfreq(labels)[:, -1])]\n",
    "    return dominant_color\n",
    "\n",
    "\n",
    "def get_colorfulness(img):\n",
    "    # split the image into its respective RGB components\n",
    "    (B, G, R) = cv2.split(img.astype(\"float\"))\n",
    "    # compute rg = R - G\n",
    "    rg = np.absolute(R - G)\n",
    "    # compute yb = 0.5 * (R + G) - B\n",
    "    yb = np.absolute(0.5 * (R + G) - B)\n",
    "    # compute the mean and standard deviation of both `rg` and `yb`\n",
    "    (rbMean, rbStd) = (np.mean(rg), np.std(rg))\n",
    "    (ybMean, ybStd) = (np.mean(yb), np.std(yb))\n",
    "    # combine the mean and standard deviations\n",
    "    stdRoot = np.sqrt((rbStd ** 2) + (ybStd ** 2))\n",
    "    meanRoot = np.sqrt((rbMean ** 2) + (ybMean ** 2))\n",
    "    # derive the \"colorfulness\" metric and return it\n",
    "    return stdRoot + (0.3 * meanRoot)\n",
    "\n",
    "\n",
    "def variance_of_laplacian(image):\n",
    "    \"\"\"compute the Laplacian of the image and then return the focus\n",
    "    measure, which is simply the variance of the Laplacian \"\"\"\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "\n",
    "def get_data_from_image(image_path):\n",
    "    img_id = os.path.basename(image_path[:-4])\n",
    "    cv_img = cv2.imread(image_path)\n",
    "    if cv_img is None:\n",
    "        print('%s cannot be converted' % image_path)\n",
    "        return pd.Series([image_path, img_id, None, None, None, None, None, None])\n",
    "    #img_size = [dat[0].size[0], dat[0].size[1]]\n",
    "    img_size = cv_img.shape[0] * cv_img.shape[1]\n",
    "    img_size_x = cv_img.shape[1]\n",
    "    img_size_y = cv_img.shape[0]\n",
    "    means, stds = cv2.meanStdDev(cv_img)\n",
    "    average_color = [int(round(means[0][0])), int(round(means[1][0])), int(round(means[2][0]))]\n",
    "    #dominant_color = get_dominant_color(cv_img)\n",
    "    #dominant_colors = [dominant_color[0], dominant_color[1], dominant_color[2]]\n",
    "    #color_stats = np.concatenate([means, stds]).flatten()\n",
    "    gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)   # image grayscale pixels\n",
    "    blurriness = variance_of_laplacian(gray)   # compute laplacian variance (blur value)\n",
    "    colorfulness = get_colorfulness(cv_img)\n",
    "\n",
    "    # color_stats.tolist()\n",
    "    return pd.Series([image_path, img_id, img_size, img_size_x, img_size_y, blurriness, colorfulness, average_color])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images features and persisting to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num images for train_jpg_1: 278167\n",
      "Total num images for train_jpg_2: 278167\n",
      "train_jpg_2 not found, will create new...\n",
      "2%: 5000 images took 65 secs, that 0.013 secs per image\n",
      "4%: 5000 images took 60 secs, that 0.012 secs per image\n",
      "5%: 5000 images took 57 secs, that 0.011 secs per image\n",
      "7%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "9%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "11%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "13%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "14%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "16%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "18%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "20%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "22%: 5000 images took 746 secs, that 0.149 secs per image\n",
      "23%: 5000 images took 741 secs, that 0.148 secs per image\n",
      "25%: 5000 images took 772 secs, that 0.154 secs per image\n",
      "/Users/ilaif/Desktop/data/avito/train_jpg_2/b98b291bd04c3d92165ca515e00468fd9756af9a8f1df42505deed1dcfb5d7ae.jpg cannot be converted\n",
      "27%: 5000 images took 1461 secs, that 0.292 secs per image\n",
      "29%: 5000 images took 642 secs, that 0.128 secs per image\n",
      "31%: 5000 images took 502 secs, that 0.1 secs per image\n",
      "32%: 5000 images took 55 secs, that 0.011 secs per image\n",
      "34%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "36%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "38%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "40%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "41%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "43%: 5000 images took 43 secs, that 0.009 secs per image\n",
      "45%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "47%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "49%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "50%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "52%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "54%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "56%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "58%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "59%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "61%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "63%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "65%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "67%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "68%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "70%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "72%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "74%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "75%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "77%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "79%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "81%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "83%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "84%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "86%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "88%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "90%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "92%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "93%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "95%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "97%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "99%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "100%: 5000 images took 30 secs, that 0.006 secs per image\n",
      "Total num images for train_jpg_3: 278167\n",
      "train_jpg_3 not found, will create new...\n",
      "2%: 5000 images took 59 secs, that 0.012 secs per image\n",
      "4%: 5000 images took 57 secs, that 0.011 secs per image\n",
      "5%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "7%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "9%: 5000 images took 55 secs, that 0.011 secs per image\n",
      "11%: 5000 images took 59 secs, that 0.012 secs per image\n",
      "13%: 5000 images took 58 secs, that 0.012 secs per image\n",
      "14%: 5000 images took 56 secs, that 0.011 secs per image\n",
      "16%: 5000 images took 57 secs, that 0.011 secs per image\n",
      "18%: 5000 images took 57 secs, that 0.011 secs per image\n",
      "20%: 5000 images took 57 secs, that 0.011 secs per image\n",
      "22%: 5000 images took 56 secs, that 0.011 secs per image\n",
      "23%: 5000 images took 60 secs, that 0.012 secs per image\n",
      "25%: 5000 images took 59 secs, that 0.012 secs per image\n",
      "27%: 5000 images took 56 secs, that 0.011 secs per image\n",
      "29%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "31%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "32%: 5000 images took 55 secs, that 0.011 secs per image\n",
      "34%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "36%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "38%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "40%: 5000 images took 55 secs, that 0.011 secs per image\n",
      "41%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "43%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "45%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "47%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "49%: 5000 images took 53 secs, that 0.011 secs per image\n",
      "50%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "52%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "54%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "56%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "58%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "59%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "61%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "63%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "65%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "67%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "68%: 5000 images took 53 secs, that 0.011 secs per image\n",
      "70%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "72%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "74%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "75%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "77%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "79%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "81%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "83%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "84%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "86%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "88%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "90%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "92%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "93%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "95%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "97%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "99%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "100%: 5000 images took 32 secs, that 0.006 secs per image\n",
      "Total num images for train_jpg_4: 278167\n",
      "train_jpg_4 not found, will create new...\n",
      "2%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "4%: 5000 images took 53 secs, that 0.011 secs per image\n",
      "5%: 5000 images took 53 secs, that 0.011 secs per image\n",
      "7%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "9%: 5000 images took 50 secs, that 0.01 secs per image\n",
      "11%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "13%: 5000 images took 52 secs, that 0.01 secs per image\n",
      "14%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "16%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "18%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "20%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "22%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "23%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "25%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "27%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "29%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "31%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "32%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "34%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "36%: 5000 images took 47 secs, that 0.009 secs per image\n",
      "38%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "40%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "41%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "43%: 5000 images took 45 secs, that 0.009 secs per image\n",
      "45%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "47%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "49%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "50%: 5000 images took 48 secs, that 0.01 secs per image\n",
      "52%: 5000 images took 49 secs, that 0.01 secs per image\n",
      "54%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "56%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "58%: 5000 images took 54 secs, that 0.011 secs per image\n",
      "59%: 5000 images took 55 secs, that 0.011 secs per image\n",
      "61%: 5000 images took 53 secs, that 0.011 secs per image\n",
      "63%: 5000 images took 41 secs, that 0.008 secs per image\n",
      "65%: 5000 images took 40 secs, that 0.008 secs per image\n",
      "67%: 5000 images took 42 secs, that 0.008 secs per image\n",
      "68%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "70%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "72%: 5000 images took 41 secs, that 0.008 secs per image\n",
      "74%: 5000 images took 44 secs, that 0.009 secs per image\n",
      "75%: 5000 images took 55 secs, that 0.011 secs per image\n",
      "77%: 5000 images took 46 secs, that 0.009 secs per image\n",
      "79%: 5000 images took 66 secs, that 0.013 secs per image\n",
      "81%: 5000 images took 51 secs, that 0.01 secs per image\n",
      "83%: 5000 images took 36 secs, that 0.007 secs per image\n",
      "84%: 5000 images took 35 secs, that 0.007 secs per image\n",
      "86%: 5000 images took 34 secs, that 0.007 secs per image\n",
      "88%: 5000 images took 32 secs, that 0.006 secs per image\n",
      "90%: 5000 images took 31 secs, that 0.006 secs per image\n",
      "92%: 5000 images took 31 secs, that 0.006 secs per image\n",
      "93%: 5000 images took 31 secs, that 0.006 secs per image\n",
      "95%: 5000 images took 29 secs, that 0.006 secs per image\n",
      "97%: 5000 images took 29 secs, that 0.006 secs per image\n",
      "99%: 5000 images took 31 secs, that 0.006 secs per image\n",
      "100%: 5000 images took 19 secs, that 0.004 secs per image\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/Users/ilaif/Desktop/data/avito'\n",
    "NAMES = ['train_jpg_2', 'train_jpg_3', 'train_jpg_4']\n",
    "for name in NAMES:\n",
    "    img_path = os.path.join(DATA_PATH, name)\n",
    "    \n",
    "    img_paths_df = pd.DataFrame([x.path for x in os.scandir(img_path) if x.path.endswith('.jpg')])\n",
    "    img_paths_df.columns = ['img_path']\n",
    "    img_count = img_paths_df.shape[0]\n",
    "    print('Total num images for %s: %s' % (name, img_count))\n",
    "\n",
    "    try:\n",
    "        df = load_df(DATA_PATH, name)\n",
    "    except FileNotFoundError:\n",
    "        print('%s not found, will create new...' % name)\n",
    "        df = None\n",
    "\n",
    "    if df is not None:\n",
    "        img_paths_df = img_paths_df[~img_paths_df['img_path'].isin(df['img_path'])]\n",
    "\n",
    "    chunk_size = 5000\n",
    "    for chunk in chunks(img_paths_df, chunk_size):\n",
    "        start_time = time.time()\n",
    "        def paralleled_func(data):\n",
    "            return data['img_path'].apply(get_data_from_image)\n",
    "        img_df = parallel_df(chunk, paralleled_func, num_cores=6, num_partitions=18)\n",
    "        columns = ['img_path', 'img_id', 'img_size', 'img_size_x', 'img_size_y', 'img_blurriness', 'img_colorfulness', 'img_color_avg',]\n",
    "        img_df.columns = columns\n",
    "        total_secs = round(time.time() - start_time)\n",
    "\n",
    "        df = img_df if df is None else pd.concat([df, img_df])\n",
    "        save_df(df, DATA_PATH, name)\n",
    "\n",
    "        perc = round(float(df.shape[0] * 100 / img_count))\n",
    "        print('%s%%: %s images took %s secs, that %s secs per image' % (perc, chunk_size, total_secs, round(float(total_secs / chunk_size), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
